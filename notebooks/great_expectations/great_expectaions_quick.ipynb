{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302902b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create the complete workflow using PostgreSQL database\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Import required modules for SQL validation\n",
    "import great_expectations as gx\n",
    "\n",
    "# Create Data Context\n",
    "context = gx.get_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96751ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to data - Using Fluent API for SQL validation\n",
    "# Using the official GX Postgres connection string\n",
    "connection_string = \"postgresql+psycopg2://try_gx:try_gx@postgres.workshops.greatexpectations.io/gx_example_db\"\n",
    "\n",
    "# Create Data Source using Fluent API\n",
    "data_source = context.sources.add_postgres(\n",
    "    \"postgres db\", connection_string=connection_string\n",
    ")\n",
    "\n",
    "# Create Data Asset using Fluent API\n",
    "data_asset = data_source.add_table_asset(name=\"taxi data\", table_name=\"nyc_taxi_data\")\n",
    "\n",
    "# Create Batch Request using Fluent API\n",
    "batch_request = data_asset.build_batch_request()\n",
    "\n",
    "# Get Batch using Fluent API\n",
    "batch_list = data_asset.get_batch_list_from_batch_request(batch_request)\n",
    "batch = batch_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Expectation Suite using Fluent API\n",
    "suite = context.add_expectation_suite(\"sql_validation_suite\")\n",
    "\n",
    "# Add expectations using Fluent API\n",
    "# First expectation: passenger_count between 1 and 6 (warning level)\n",
    "expectation1 = gx.core.ExpectationConfiguration(\n",
    "    expectation_type='expect_column_values_to_be_between',\n",
    "    kwargs={'column': 'passenger_count', 'min_value': 1, 'max_value': 6}\n",
    ")\n",
    "suite.add_expectation(expectation1)\n",
    "\n",
    "# Second expectation: fare_amount >= 0 (critical level)\n",
    "expectation2 = gx.core.ExpectationConfiguration(\n",
    "    expectation_type='expect_column_values_to_be_between',\n",
    "    kwargs={'column': 'fare_amount', 'min_value': 0}\n",
    ")\n",
    "suite.add_expectation(expectation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Checkpoint using Fluent API\n",
    "checkpoint_config = {\n",
    "    'name': 'sql_checkpoint',\n",
    "    'config_version': 1.0,\n",
    "    'class_name': 'Checkpoint',\n",
    "    'run_name_template': '%Y%m%d-%H%M%S-sql-run',\n",
    "    'expectation_suite_name': suite.expectation_suite_name,\n",
    "    'batch_request': {\n",
    "        'datasource_name': data_source.name,\n",
    "        'data_asset_name': data_asset.name\n",
    "    },\n",
    "    'action_list': [\n",
    "        {\n",
    "            'name': 'store_validation_result',\n",
    "            'action': {'class_name': 'StoreValidationResultAction'}\n",
    "        },\n",
    "        {\n",
    "            'name': 'update_data_docs',\n",
    "            'action': {'class_name': 'UpdateDataDocsAction'}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "checkpoint = context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Checkpoint using Fluent API\n",
    "checkpoint_result = context.run_checkpoint(checkpoint_name=checkpoint.name)\n",
    "\n",
    "# Display results using Fluent API\n",
    "print(f\"Success: {checkpoint_result.success}\")\n",
    "print(f\"Statistics: {checkpoint_result.get_statistics()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd16028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Fluent API Demonstration\n",
    "# This cell demonstrates ALL Fluent API methods including documentation access\n",
    "\n",
    "# Get documentation site information\n",
    "docs_sites = context.get_docs_sites_urls()\n",
    "\n",
    "# Get expectation suite details using Fluent API\n",
    "try:\n",
    "    suite = context.get_expectation_suite('sql_checkpoint')\n",
    "    print(f\"Suite Name: {suite.expectation_suite_name}\")\n",
    "    print(f\"Number of Expectations: {len(suite.expectations)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing suite: {e}\")\n",
    "\n",
    "# Get checkpoint results using Fluent API\n",
    "try:\n",
    "    checkpoint_result = context.run_checkpoint(checkpoint_name='sql_checkpoint')\n",
    "    print(f\"Checkpoint Success: {checkpoint_result.success}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing checkpoint: {e}\")\n",
    "\n",
    "# Open Data Docs in browser\n",
    "try:\n",
    "    context.open_data_docs()\n",
    "except Exception as e:\n",
    "    print(f\"Could not open browser: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b0f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Fluent API Demonstration - Using Database + Separate Profiling Suite\n",
    "# This cell demonstrates ALL Fluent API methods using PostgreSQL database with separate suites\n",
    "# Create organized output directories specifically for Great Expectations demo\n",
    "output_dir = Path(\"notebooks/great_expectations/outputs\")\n",
    "profiling_dir = output_dir / \"profiling\"\n",
    "manual_dir = output_dir / \"manual\"\n",
    "reports_dir = output_dir / \"reports\"\n",
    "\n",
    "# Ensure directories exist\n",
    "for dir_path in [output_dir, profiling_dir, manual_dir, reports_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Fluent API Method 1: Create PostgreSQL Data Source (with error handling)\n",
    "data_source_name = 'postgres_demo'\n",
    "try:\n",
    "    # Try to get existing data source first\n",
    "    data_source = context.get_datasource(data_source_name)\n",
    "    print(f'‚úÖ Using existing PostgreSQL Data Source: {data_source.name}')\n",
    "except:\n",
    "    # Create new PostgreSQL data source\n",
    "    connection_string = \"postgresql+psycopg2://try_gx:try_gx@postgres.workshops.greatexpectations.io/gx_example_db\"\n",
    "    data_source = context.sources.add_postgres(data_source_name, connection_string=connection_string)\n",
    "    print(f'‚úÖ Created new PostgreSQL Data Source: {data_source.name}')\n",
    "\n",
    "# Fluent API Method 2: Create Table Data Asset (with error handling)\n",
    "asset_name = 'nyc_taxi_data'\n",
    "try:\n",
    "    data_asset = data_source.get_asset(asset_name)\n",
    "    print(f'‚úÖ Using existing Table Asset: {data_asset.name}')\n",
    "except:\n",
    "    data_asset = data_source.add_table_asset(name=asset_name, table_name=\"nyc_taxi_data\")\n",
    "    print(f'‚úÖ Created new Table Asset: {data_asset.name}')\n",
    "\n",
    "# Fluent API Method 3: Build Batch Request\n",
    "batch_request = data_asset.build_batch_request()\n",
    "print(f\"‚úÖ Fluent Batch Request created\")\n",
    "\n",
    "# Fluent API Method 4: Get Batch List\n",
    "batch_list = data_asset.get_batch_list_from_batch_request(batch_request)\n",
    "batch = batch_list[0]\n",
    "print(f\"‚úÖ Fluent Batch created: {batch.id}\")\n",
    "\n",
    "# Create SEPARATE expectation suites for different purposes\n",
    "print(\"\\nüìã Creating Separate Expectation Suites:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Suite 1: For GX Profiling Tool (Automatic Data Quality Analysis)\n",
    "profiling_suite_name = 'database_profiling_suite'\n",
    "try:\n",
    "    profiling_suite = context.get_expectation_suite(profiling_suite_name)\n",
    "    print(f'‚úÖ Using existing Profiling Suite: {profiling_suite.expectation_suite_name}')\n",
    "except:\n",
    "    profiling_suite = context.add_expectation_suite(profiling_suite_name)\n",
    "    print(f'‚úÖ Created new Profiling Suite: {profiling_suite.expectation_suite_name}')\n",
    "\n",
    "# Suite 2: For Manual Expectations (Business Rules)\n",
    "manual_suite_name = 'database_manual_suite'\n",
    "try:\n",
    "    manual_suite = context.get_expectation_suite(manual_suite_name)\n",
    "    print(f'‚úÖ Using existing Manual Suite: {manual_suite.expectation_suite_name}')\n",
    "except:\n",
    "    manual_suite = context.add_expectation_suite(manual_suite_name)\n",
    "    print(f'‚úÖ Created new Manual Suite: {manual_suite.expectation_suite_name}')\n",
    "\n",
    "# Use GX Profiling Tool - This generates automatic data quality insights!\n",
    "print(\"\\nüîç Using GX Profiling Tool (Separate Suite):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# The profiling tool automatically analyzes data and creates expectations\n",
    "profiler = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=profiling_suite.expectation_suite_name\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Profiler created: {profiler}\")\n",
    "\n",
    "# Run automatic profiling to generate data quality insights\n",
    "print(\"üîÑ Running automatic data profiling...\")\n",
    "profiler_result = profiler.validate()\n",
    "print(f\"‚úÖ Profiling completed\")\n",
    "\n",
    "# Save the profiling suite\n",
    "profiler.save_expectation_suite()\n",
    "print(\"‚úÖ Profiling suite saved\")\n",
    "\n",
    "# Add manual expectations using a separate suite (this is the proper way)\n",
    "print(\"\\nüîß Adding Manual Expectations (Separate Suite):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=manual_suite.expectation_suite_name\n",
    ")\n",
    "\n",
    "# Add business-specific expectations\n",
    "validator.expect_column_values_to_be_between(\n",
    "    column='passenger_count',\n",
    "    min_value=1,\n",
    "    max_value=6\n",
    ")\n",
    "\n",
    "validator.expect_column_values_to_be_between(\n",
    "    column='fare_amount',\n",
    "    min_value=0\n",
    ")\n",
    "\n",
    "validator.expect_column_values_to_not_be_null(\n",
    "    column='trip_distance'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Added {len(validator.get_expectation_suite().expectations)} manual expectations\")\n",
    "\n",
    "# Save the manual expectation suite\n",
    "validator.save_expectation_suite()\n",
    "print(\"‚úÖ Manual expectation suite saved\")\n",
    "\n",
    "# Create SEPARATE checkpoints for different suites\n",
    "print(\"\\nüéØ Creating Separate Checkpoints:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Checkpoint 1: For Profiling Suite\n",
    "profiling_checkpoint_name = 'database_profiling_checkpoint'\n",
    "try:\n",
    "    profiling_checkpoint = context.get_checkpoint(profiling_checkpoint_name)\n",
    "    print(f'‚úÖ Using existing Profiling Checkpoint: {profiling_checkpoint.name}')\n",
    "except:\n",
    "    profiling_checkpoint_config = {\n",
    "        'name': profiling_checkpoint_name,\n",
    "        'config_version': 1.0,\n",
    "        'class_name': 'Checkpoint',\n",
    "        'run_name_template': '%Y%m%d-%H%M%S-profiling-run',\n",
    "        'expectation_suite_name': profiling_suite.expectation_suite_name,\n",
    "        'batch_request': {\n",
    "            'datasource_name': data_source.name,\n",
    "            'data_asset_name': data_asset.name\n",
    "        },\n",
    "        'action_list': [\n",
    "            {\n",
    "                'name': 'store_validation_result',\n",
    "                'action': {'class_name': 'StoreValidationResultAction'}\n",
    "            },\n",
    "            {\n",
    "                'name': 'update_data_docs',\n",
    "                'action': {'class_name': 'UpdateDataDocsAction'}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    profiling_checkpoint = context.add_checkpoint(**profiling_checkpoint_config)\n",
    "    print(f'‚úÖ Created new Profiling Checkpoint: {profiling_checkpoint.name}')\n",
    "\n",
    "# Checkpoint 2: For Manual Suite\n",
    "manual_checkpoint_name = 'database_manual_checkpoint'\n",
    "try:\n",
    "    manual_checkpoint = context.get_checkpoint(manual_checkpoint_name)\n",
    "    print(f'‚úÖ Using existing Manual Checkpoint: {manual_checkpoint.name}')\n",
    "except:\n",
    "    manual_checkpoint_config = {\n",
    "        'name': manual_checkpoint_name,\n",
    "        'config_version': 1.0,\n",
    "        'class_name': 'Checkpoint',\n",
    "        'run_name_template': '%Y%m%d-%H%M%S-manual-run',\n",
    "        'expectation_suite_name': manual_suite.expectation_suite_name,\n",
    "        'batch_request': {\n",
    "            'datasource_name': data_source.name,\n",
    "            'data_asset_name': data_asset.name\n",
    "        },\n",
    "        'action_list': [\n",
    "            {\n",
    "                'name': 'store_validation_result',\n",
    "                'action': {'class_name': 'StoreValidationResultAction'}\n",
    "            },\n",
    "            {\n",
    "                'name': 'update_data_docs',\n",
    "                'action': {'class_name': 'UpdateDataDocsAction'}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    manual_checkpoint = context.add_checkpoint(**manual_checkpoint_config)\n",
    "    print(f'‚úÖ Created new Manual Checkpoint: {manual_checkpoint.name}')\n",
    "\n",
    "# Run BOTH checkpoints separately\n",
    "print(\"\\nüîÑ Running Separate Checkpoints:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Run Profiling Checkpoint\n",
    "print(\"üîÑ Running Profiling Checkpoint...\")\n",
    "profiling_result = context.run_checkpoint(checkpoint_name=profiling_checkpoint.name)\n",
    "print(f\"‚úÖ Profiling Checkpoint completed: {profiling_result.success}\")\n",
    "\n",
    "# Run Manual Checkpoint\n",
    "print(\"üîÑ Running Manual Checkpoint...\")\n",
    "manual_result = context.run_checkpoint(checkpoint_name=manual_checkpoint.name)\n",
    "print(f\"‚úÖ Manual Checkpoint completed: {manual_result.success}\")\n",
    "\n",
    "# Now demonstrate documentation access methods\n",
    "print(\"\\nüìö Documentation Access Methods:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Fluent API Method: Get Documentation Sites\n",
    "docs_sites = context.get_docs_sites_urls()\n",
    "print(f\"‚úÖ Data Documentation Sites: {len(docs_sites)}\")\n",
    "for site in docs_sites:\n",
    "    print(f\"  Site Name: {site['site_name']}\")\n",
    "    print(f\"  Site URL: {site['site_url']}\")\n",
    "\n",
    "# Get details for BOTH suites\n",
    "print(f\"\\nüìã Profiling Suite Details:\")\n",
    "profiling_suite = context.get_expectation_suite(profiling_suite_name)\n",
    "print(f\"‚úÖ Suite Name: {profiling_suite.expectation_suite_name}\")\n",
    "print(f\"‚úÖ Number of Expectations: {len(profiling_suite.expectations)}\")\n",
    "\n",
    "print(f\"\\nüìã Manual Suite Details:\")\n",
    "manual_suite = context.get_expectation_suite(manual_suite_name)\n",
    "print(f\"‚úÖ Suite Name: {manual_suite.expectation_suite_name}\")\n",
    "print(f\"‚úÖ Number of Expectations: {len(manual_suite.expectations)}\")\n",
    "\n",
    "# Show results for BOTH checkpoints\n",
    "print(f\"\\nüìä Profiling Checkpoint Results:\")\n",
    "print(f\"‚úÖ Success: {profiling_result.success}\")\n",
    "print(f\"‚úÖ Statistics: {profiling_result.get_statistics()}\")\n",
    "\n",
    "print(f\"\\nüìä Manual Checkpoint Results:\")\n",
    "print(f\"‚úÖ Success: {manual_result.success}\")\n",
    "print(f\"‚úÖ Statistics: {manual_result.get_statistics()}\")\n",
    "\n",
    "# Save organized outputs to Great Expectations specific directories\n",
    "print(f\"\\nüíæ Saving Great Expectations Outputs:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Save profiling results\n",
    "# Convert statistics to serializable format\n",
    "profiling_stats = profiling_result.get_statistics()\n",
    "serializable_profiling_stats = {\n",
    "    \"data_asset_count\": profiling_stats.get(\"data_asset_count\", 0),\n",
    "    \"validation_result_count\": profiling_stats.get(\"validation_result_count\", 0),\n",
    "    \"successful_validation_count\": profiling_stats.get(\"successful_validation_count\", 0),\n",
    "    \"unsuccessful_validation_count\": profiling_stats.get(\"unsuccessful_validation_count\", 0),\n",
    "    \"successful_validation_percent\": profiling_stats.get(\"successful_validation_percent\", 0.0)\n",
    "}\n",
    "\n",
    "profiling_summary = {\n",
    "    \"statistics\": serializable_profiling_stats,\n",
    "# Save manual results\n",
    "# Convert statistics to serializable format\n",
    "manual_stats = manual_result.get_statistics()\n",
    "serializable_manual_stats = {\n",
    "    \"data_asset_count\": manual_stats.get(\"data_asset_count\", 0),\n",
    "    \"validation_result_count\": manual_stats.get(\"validation_result_count\", 0),\n",
    "    \"successful_validation_count\": manual_stats.get(\"successful_validation_count\", 0),\n",
    "    \"unsuccessful_validation_count\": manual_stats.get(\"unsuccessful_validation_count\", 0),\n",
    "    \"successful_validation_percent\": manual_stats.get(\"successful_validation_percent\", 0.0)\n",
    "}\n",
    "\n",
    "manual_summary = {\n",
    "    \"suite_name\": manual_suite.expectation_suite_name,\n",
    "    \"expectations_count\": len(manual_suite.expectations),\n",
    "    \"checkpoint_success\": manual_result.success,\n",
    "    \"statistics\": serializable_manual_stats,\n",
    "    \"batch_id\": batch.id,\n",
    "    \"data_source\": data_source.name,\n",
    "    \"data_asset\": data_asset.name\n",
    "}\n",
    "\n",
    "with open(manual_dir / \"manual_summary.json\", \"w\") as f:\n",
    "    json.dump(manual_summary, f, indent=2)\n",
    "print(f\"‚úÖ Manual summary saved to: {manual_dir / 'manual_summary.json'}\")\n",
    "\n",
    "# Create comprehensive report\n",
    "report_content = f\"\"\"\n",
    "# Great Expectations Demo Validation Report\n",
    "\n",
    "## Project Information\n",
    "- **Project Root**: {Path.cwd()}\n",
    "- **Great Expectations Output Directory**: {output_dir}\n",
    "- **Profiling Results**: {profiling_dir}\n",
    "- **Manual Results**: {manual_dir}\n",
    "- **Reports**: {reports_dir}\n",
    "- **Notebook**: notebooks/great_expectations/demo.ipynb\n",
    "\n",
    "## Database Integration\n",
    "- **Data Source**: {data_source.name}\n",
    "- **Data Asset**: {data_asset.name}\n",
    "- **Batch ID**: {batch.id}\n",
    "- **Connection**: PostgreSQL (Official GX Workshop Database)\n",
    "\n",
    "## Expectation Suites\n",
    "\n",
    "### Profiling Suite (Automatic Data Quality Analysis)\n",
    "- **Name**: {profiling_suite.expectation_suite_name}\n",
    "- **Expectations**: {len(profiling_suite.expectations)}\n",
    "- **Checkpoint Success**: {profiling_result.success}\n",
    "- **Purpose**: Automatic data profiling and quality insights\n",
    "\n",
    "### Manual Suite (Business Rules)\n",
    "- **Name**: {manual_suite.expectation_suite_name}\n",
    "- **Expectations**: {len(manual_suite.expectations)}\n",
    "- **Checkpoint Success**: {manual_result.success}\n",
    "- **Purpose**: Custom business rules and validation logic\n",
    "\n",
    "## Validation Results\n",
    "\n",
    "### Profiling Checkpoint Results\n",
    "- **Success**: {profiling_result.success}\n",
    "- **Statistics**: {profiling_result.get_statistics()}\n",
    "\n",
    "### Manual Checkpoint Results\n",
    "- **Success**: {manual_result.success}\n",
    "- **Statistics**: {manual_result.get_statistics()}\n",
    "\n",
    "## Documentation\n",
    "- **Data Docs Sites**: {len(docs_sites)}\n",
    "- **Interactive HTML**: Available via context.open_data_docs()\n",
    "- **Site URL**: {docs_sites[0]['site_url'] if docs_sites else 'N/A'}\n",
    "\n",
    "## Fluent API Methods Demonstrated\n",
    "- ‚úÖ context.sources.add_postgres() - PostgreSQL data source\n",
    "- ‚úÖ data_source.add_table_asset() - Table asset creation\n",
    "- ‚úÖ data_asset.build_batch_request() - Batch request building\n",
    "- ‚úÖ data_asset.get_batch_list_from_batch_request() - Batch list creation\n",
    "- ‚úÖ context.add_expectation_suite() - Expectation suite creation\n",
    "- ‚úÖ context.get_validator() - Validator creation (GX Automatic Validator Tool)\n",
    "- ‚úÖ validator.validate() - Profiling and validation execution\n",
    "- ‚úÖ validator.expect_*() - Manual expectation addition\n",
    "- ‚úÖ validator.save_expectation_suite() - Suite saving\n",
    "- ‚úÖ context.add_checkpoint() - Checkpoint creation\n",
    "- ‚úÖ context.run_checkpoint() - Checkpoint execution\n",
    "- ‚úÖ context.get_docs_sites_urls() - Documentation site access\n",
    "- ‚úÖ context.get_expectation_suite() - Suite details retrieval\n",
    "\n",
    "## Next Steps\n",
    "1. Review validation results in Data Docs\n",
    "2. Customize expectations for your specific use case\n",
    "3. Integrate with your data pipeline\n",
    "4. Set up automated validation schedules\n",
    "5. Explore additional expectation types\n",
    "\n",
    "## File Structure\n",
    "```\n",
    "notebooks/great_expectations/\n",
    "‚îú‚îÄ‚îÄ demo.ipynb                    # This notebook\n",
    "‚îî‚îÄ‚îÄ outputs/                      # Generated outputs\n",
    "    ‚îú‚îÄ‚îÄ profiling/                # Profiling results\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ profiling_summary.json\n",
    "    ‚îú‚îÄ‚îÄ manual/                   # Manual validation results\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ manual_summary.json\n",
    "    ‚îî‚îÄ‚îÄ reports/                  # Generated reports\n",
    "        ‚îî‚îÄ‚îÄ validation_report.md\n",
    "```\n",
    "\n",
    "Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "with open(reports_dir / \"validation_report.md\", \"w\") as f:\n",
    "    f.write(report_content)\n",
    "print(f\"‚úÖ Comprehensive report saved to: {reports_dir / 'validation_report.md'}\")\n",
    "\n",
    "# Create a simple index file for easy navigation\n",
    "index_content = f\"\"\"\n",
    "# Great Expectations Demo Outputs\n",
    "\n",
    "This directory contains outputs generated from the Great Expectations demo notebook.\n",
    "\n",
    "## Directory Structure\n",
    "- **profiling/** - Automatic data profiling results\n",
    "- **manual/** - Manual validation results  \n",
    "- **reports/** - Comprehensive reports and documentation\n",
    "\n",
    "## Files Generated\n",
    "- `profiling/profiling_summary.json` - Profiling suite summary\n",
    "- `manual/manual_summary.json` - Manual suite summary\n",
    "- `reports/validation_report.md` - Complete validation report\n",
    "\n",
    "## Data Docs\n",
    "Interactive HTML documentation is available at:\n",
    "{docs_sites[0]['site_url'] if docs_sites else 'Run the notebook to generate Data Docs'}\n",
    "\n",
    "Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "with open(output_dir / \"README.md\", \"w\") as f:\n",
    "    f.write(index_content)\n",
    "print(f\"‚úÖ Index file saved to: {output_dir / 'README.md'}\")\n",
    "\n",
    "\n",
    "print(\"\\nüåê Opening Data Docs in Browser...\")\n",
    "try:\n",
    "    context.open_data_docs()\n",
    "    print(\"‚úÖ Data Docs opened in browser\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Could not open browser automatically: {e}\")\n",
    "    print(\"You can manually open the URL shown above in your browser\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
